[{"name":"app.R","content":"library(shiny)\nlibrary(shinythemes)\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(DT)\nlibrary(plotly)\nlibrary(factoextra)\nlibrary(corrplot)\nlibrary(mclust)\n\n\nif (FALSE) library(munsell)\n\n\nui <- navbarPage(\"Clustering Dashboard\",\n  theme = shinytheme(\"flatly\"),\n  tabPanel(\n    \"Hierarchical Clustering Dashboard\",\n    fluidPage(\n      sidebarLayout(\n        sidebarPanel(\n          h4(\"Clustering Parameters\"),\n          selectInput(\"dataset\", \"Select Dataset: \",\n                      choices = list(\n                        \"Iris Dataset\" = \"iris\",\n                        \"Random Gaussian Clusters\" = \"random_gaussian\"\n                      ), selected = \"iris\"),\n          selectInput(\"linkage\", \"Linkage Method: \",\n                      choices = list(\n                        \"Complete\" = \"complete\",\n                        \"Average\" = \"average\",\n                        \"Single\" = \"single\",\n                        \"Ward\" = \"ward\"\n                      ), selected = \"complete\"),\n          helpText(\"Pay attention to how the height scale changes when choosing between different linkage methods.\"), \n          selectInput(\"distance\", \"Distance Method: \",\n                      choices = list(\n                        \"Euclidean\" = \"euclidean\",\n                        \"Manhattan\" = \"manhattan\"\n                      )),\n          numericInput(\"n_clusters\", \"Number of clusters: \",\n                       value = 3, min = 2, max = 10, step = 1),\n          \n          checkboxInput(\"scale_data\", \"Scale Data\", value = TRUE),\n          \n          actionButton(\"run_clustering\", \"Run Clustering\", class = 'btn-primary')\n        ),\n        mainPanel(\n          tabsetPanel(\n            tabPanel(\"Dendogram\",\n                     plotlyOutput(\"dendogram\", height = \"600px\"),\n                     fluidRow(\n                       column(12,\n                              h4(\"Interpretation\"),\n                              textOutput(\"interpretation1\")\n                       )\n                     ),\n                     br(),\n                     br(),\n                     br()\n            ),\n            tabPanel(\"Cluster Visualization\",\n                     plotlyOutput(\"cluster_plot\", height = \"600px\"),\n                     fluidRow(\n                       column(12,\n                              h4(\"Interpretation\"),\n                              textOutput(\"interpretation2\")\n                       )\n                     ),\n                     br(),\n                     br(),\n                     br()\n            ),\n            tabPanel(\"Correlation Matrix\",\n                     plotOutput(\"correlation_plot\")\n            )\n          )\n        )\n      )\n    )\n  ),\n  \n  tabPanel(\n    \"Non-Hierarchical Clustering Methods\",\n    fluidPage(\n      sidebarLayout(\n        sidebarPanel(\n          h4(\"Clustering Parameters\"),\n          selectInput(\"dataset2\", \"Select Dataset: \",\n                      choices = list(\n                        \"Iris Dataset\" = \"iris\",\n                        \"Random Gaussian Clusters\" = \"random_gaussian\"\n                      ), selected = \"iris\"),\n          selectInput(\"method\", \"Clustering Algorithm\",\n                      choices = list(\n                        \"K-means\" = \"kmeans\",\n                        \"Gaussian Mixture Model\" = \"gmm\"\n                      )),\n          numericInput(\"n_clusters_alt\", \"Number of clusters: \",\n                       value = 3, min = 2, max = 10, step = 1),\n          checkboxInput(\"scale_data_2\", \"Scale Data\", value = TRUE),\n          actionButton(\"run_clustering_2\", \"Run Clustering\", class = 'btn-primary')\n        ),\n        mainPanel(\n          tabsetPanel(\n            tabPanel(\"Cluster Visualization\",\n                     plotlyOutput(\"cluster_plot_2\", height = \"600px\"),\n                     fluidRow(\n                       column(12,\n                              h4(\"Interpretation\"),\n                              textOutput(\"interpretation3\"))\n                     ),\n                     br(),\n                     br(),\n                     br()\n            )\n          )\n        )\n      )\n    )\n  ),\n  footer = tags$footer(\n    style = \"\n      position: fixed;\n      bottom: 0;\n      left: 0;\n      width: 100%;\n      background-color: #f8f9fa;\n      border-top: 1px solid #ddd;\n      text-align: center;\n      padding: 8px;\n      font-size: 12px;\n      color: #6c757d;\n      z-index: 1000;\n    \",\n    \"2025 Created by Shahriar Shams and Issey Sone\"\n  )\n)\n\n\nserver <- function(input, output, session) {\n  \n  generate_sample_data <- function(dataset, n_samples = 250) {\n    set.seed(123)\n    sigma1 <- matrix(c(1, 0.2, 0.2, 1), ncol = 2)\n    sigma2 <- matrix(c(1, -0.3, -0.3, 1), ncol = 2)\n    sigma3 <- matrix(c(1, 0, 0, 1), ncol = 2)\n    switch(dataset,\n           \"iris\" = {\n             data(iris)\n             return(iris[, 1:4])\n           },\n           \"random_gaussian\" = {\n             data.frame(\n               x1 = c(rnorm(n_samples/3, mean = 2, sd = 0.5),\n                      rnorm(n_samples/3, mean = 6, sd = 0.7),\n                      rnorm(n_samples/3, mean = 4, sd = 0.4)),\n               x2 = c(rnorm(n_samples/3, mean = 2, sd = 0.6),\n                      rnorm(n_samples/3, mean = 6, sd = 0.5),\n                      rnorm(n_samples/3, mean = 8, sd = 0.7)),\n               x3 = c(rnorm(n_samples/3, mean = 1, sd = 0.3),\n                      rnorm(n_samples/3, mean = 5, sd = 0.4),\n                      rnorm(n_samples/3, mean = 3, sd = 0.5))\n             )\n           }\n           )\n  }\n  data_reactive <- reactive({\n    if(input$dataset == \"iris\") {\n      generate_sample_data(\"iris\")\n    } else {\n      n_samples <- 250\n      generate_sample_data(input$dataset, n_samples)\n    }\n  })\n  \n  clustering_results <- eventReactive(input$run_clustering, {\n    data <- data_reactive()\n    \n    if (input$scale_data) {\n      data_scaled <- scale(data)\n    } else {\n      data_scaled <- data\n    }\n    \n    dist_matrix <- dist(data_scaled, method = input$distance)\n    \n    hc <- hclust(dist_matrix, method = input$linkage)\n    \n    clusters <- cutree(hc, k = input$n_clusters)\n    \n    list(\n      data = data,\n      data_scaled = data_scaled,\n      hc = hc,\n      clusters = clusters,\n      dist_matrix = dist_matrix\n    )\n    \n  })\n  \n  output$dendogram <- renderPlotly({\n    req(clustering_results())\n    \n    results <- clustering_results()\n    \n    p <- fviz_dend(results$hc, k = input$n_clusters,\n                   cex = 0.5, k_colors = \"jco\",\n                   color_labels_by_k = TRUE, rect = TRUE, rect_fill = TRUE, rect_border = \"jco\") +\n      labs(title = \"Hierarchical Clustering Dendogram\") +\n      theme_minimal()\n    ggplotly(p, tooltip = 'text')\n  })\n  \n  output$cluster_plot <- renderPlotly({\n    req(clustering_results())\n    results <- clustering_results()\n    \n    data_with_clusters <- cbind(results$data, Cluster = as.factor(results$clusters))\n    \n    if (ncol(results$data) > 2) {\n      pca <- prcomp(results$data_scaled)\n      plot_data <- data.frame(\n        PC1 = pca$x[, 1],\n        PC2 = pca$x[, 2],\n        Cluster = as.factor(results$clusters)\n      )\n      \n      p <- ggplot(plot_data, aes(x = PC1, y = PC2, color = Cluster)) +\n        geom_point(size = 3, alpha = 0.7) +\n        labs(title = \"Clusters (PCA) Projection\", x = \"First Principal Component\", y = \"Second Principal Component\") + \n        theme_minimal() +\n        scale_color_brewer(palette = \"Set1\")\n    } else {\n      plot_data <- data.frame(\n        x = results$data[, 1],\n        y = results$data[, 2],\n        Cluster = as.factor(results$clusters)\n      )\n      \n      p <- ggplot(plot_data, aes(x = x, y = y, color = Cluster)) + \n        geom_point(size = 3, alpha = 0.7) +\n        labs(tilte = \"Clusters\",\n             x = names(results$data)[1],\n             y = names(results$data)[2]) +\n        theme_minimal() +\n        scale_color_brewer(palette = \"Set1\")\n    }\n    \n    ggplotly(p)\n  })\n  data_reactive_2 <- reactive({\n    if(input$dataset2 == \"iris\") {\n      generate_sample_data(\"iris\")\n    } else {\n      n_samples <- 250\n      generate_sample_data(input$dataset2, n_samples)\n    }\n  })\n  \n  output$correlation_plot <- renderPlot({\n    data <- data_reactive_2()\n    if (ncol(data) > 1) {\n      cor_matrix <- cor(data)\n      corrplot(cor_matrix, method = \"color\", type = \"upper\", order = \"hclust\")\n    }\n    \n  })\n  \n  \n  clustering_results_2 <- eventReactive(input$run_clustering_2, {\n    data <- data_reactive_2()\n    if(input$scale_data_2) {\n      data_scaled <- scale(data)\n    } else {\n      data_scaled <- data\n    }\n    \n    if (input$method == \"kmeans\") {\n      model <- kmeans(data_scaled, centers = input$n_clusters_alt)\n      clusters <- model$cluster\n    } else if (input$method == \"gmm\") {\n      model <- Mclust(data_scaled, G = input$n_clusters_alt)\n      clusters <- model$classification\n    }\n    \n    list(\n      data = data,\n      data_scaled = data_scaled,\n      clusters = clusters\n    )\n    \n  })\n  \n  output$cluster_plot_2 <- renderPlotly({\n    req(clustering_results_2())\n    results <- clustering_results_2()\n    \n    pca <- prcomp(results$data_scaled)\n    \n    plot_data <- data.frame(\n      PC1 = pca$x[, 1],\n      PC2 = pca$x[, 2],\n      Cluster = as.factor(results$clusters)\n    )\n    \n    p <- ggplot(plot_data, aes(x = PC1, y = PC2, color = Cluster)) + \n      geom_point(size = 3, alpha = 0.7) +\n      labs(title = paste(input$method, \"Clustering Projection\"),\n           x = \"First Principal Component\",\n           y = \"Second Principal Component\") +\n      theme_minimal() + \n      scale_color_brewer(palette = \"Set1\")\n    \n    ggplotly(p)\n    \n  })\n  \n  # Interpretations\n  \n  output$interpretation1 <- renderText({\n    \n    \"In a dendogram look at the vertical lines (merge heights) to understand cluster similarity, shorter merges means clusters are combined with lower distance (higher similarity),\n    tall merges means larger distance (lower similarity). Horizontal cluster widths are an indicator of how many points each branch contains wider clusters contain more points, whilst\n    narrower clusters are smaller, tightly related groups. \n    The four linkage methods determine how distance between two clusters is measured when merging clusters. Pay attention to how each of these can change the dendogram.\n    The number of clusters determines where the dendogram is\n    'cut' higher number of clusters means you cut lower and capture earlier short merges, less clusters means you have taller merges and you cut higher.\"\n  })\n  \n  output$interpretation2 <- renderText({\n    \"For the PCA projection, check if the clusters are well seperated or if they are overlapping. If clusters are overlapping heavily, then the seperation might be weak or could potentailly\n    be merged. You can also check for the compactness of clusters,\n    larger clusters could be broken down more or could have higher variance. Since PC1 explains the largest variance, clusters far apart along PC1 differ the most in\n    features. \"\n  })\n}\n\n\n\n\nshinyApp(ui = ui, server = server)","type":"text"}]
